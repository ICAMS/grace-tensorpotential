seed: 1
cutoff: 6

data:
  distributed: True
#  distribute_values: True
  path: "tf_dataset/stage3"
  train_size: 4 #  num of batches (int)
  #  test_path: "test_dataset/stage3"
  #  test_shards: 1 # num of shards (int)
  test_size: 2 #  num of batches (int)

potential:
  #  elements: ["C", "H", "O"]
  preset: "FS"
  scale: True

fit:
  #  strategy: mirrored
  loss: {
    energy: { weight: 1. }, #normalize_by_samples: False},
    forces: { weight: 5. }, # normalize_by_samples: False},

    #    switch: { after_iter: 1, energy: { weight: 10 }, forces: { weight: 100 } }
  }

  #  normalize_weights: True  # norm per-sample weights to sum-up to one
  #  normalize_force_per_structure: True # force-weights is divided by number of atoms

  optimizer: Adam
  opt_params: { "learning_rate": 0.01, "amsgrad": True }
  learning_rate_reduction: { patience: 5, factor: 0.8, min: 1.0e-3, stop_at_min: True, resume_lr: True }
  #  optimizer: L-BFGS-B
  maxiter: 2

  eval_init_stats: True
#  trainable_variable_names: ["Z/ChemicalEmbedding"] ### specify trainable variables name pattern

  #  batch_size: 10
  #  test_batch_size: 20
  #  train_max_n_buckets: 2
  #  test_max_n_buckets: 2


  checkpoint_freq: 20
  progressbar: True
  train_shuffle: True
  jit_compile: True
